{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef915ead-855f-497b-bf5b-05e7122b4643",
   "metadata": {},
   "source": [
    "# MODELOS COMPUTACIONALES II: Proyecto Final\n",
    "### Vladimir Abisai Espinosa Torrijos\n",
    "El proyecto debe desarrollar las habilidades aprendidas a lo largo del semestre: \n",
    "- Analisis de dataset\n",
    "- Identificacion del tipo de problema (clasificacion o regresion)\n",
    "- Creacion de propuestas de modelos (que modelo supervisado utilizar, como crear la ANN o CNN a utilizar)\n",
    "- Evaluacion de resultados acorde al problema (clasificacion: accuracy, precision, recall, f1; regresion: mse, rmse, r^2, etc)\n",
    "- Analisis de resultados (determinar el mejor resultado posible y justificar por que es el mejor)\n",
    "- El resultado debe de ser interpretable\n",
    "\n",
    "## Nota: El proyecto lo realize en Pycharm, por lo que no contiene la forma habitual de un notebook de Jupyter (este archivo solo lo hice para subirlo al repositorio con la explicacion del codigo). Dado esto, las imagenes de los resultados (graficos) solo se pueden visualizar si el codigo se ejecuta en pycharm, ademas las subi a drive por si desea verlos sin ejecutar el codigo: \n",
    "## https://drive.google.com/drive/folders/1q6L2OGNPsHmLaEjq0t7iyTeysCsa2w95?usp=sharing\n",
    "\n",
    "## Las preguntas del proyecto las contesto al final del archivo ☻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c0631-9574-478c-b047-2a2580853510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siempre importo todas las librerias y funciones al comienzo, no me gusta colocarlas en medio del codigo.\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# la ruta de acceso para el dataset completo :D\n",
    "dataset_path = r\"C:\\Users\\vladi\\OneDrive\\Documentos\\dataset_proyecto_MII\\dataset\"\n",
    "\n",
    "# tamaño al que se redimensionan las imágenes. Este paso es mega importante porque la maquina debe aprender en base a todas las imagenes, y si tienen tamaños diferentes esto seria fatal.\n",
    "IMG_SIZE = 128\n",
    "\n",
    "# dict de las etiquetas\n",
    "labels_dict = {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
    "label_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# cargue las imágenes con una funcion nomas para que fuera mas limpio el codigo y no tener todo de manera 100% lineal y desordenada. Funcinaria pero no me gusta.\n",
    "def load_images(folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in labels_dict:\n",
    "        folder_path = os.path.join(folder, category)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append(img)\n",
    "                labels.append(labels_dict[category])\n",
    "            except:\n",
    "                continue\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "train_data, train_labels = load_images(os.path.join(dataset_path, 'Training'))\n",
    "test_data, test_labels = load_images(os.path.join(dataset_path, 'Testing'))\n",
    "\n",
    "# normalizar\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "test_data = np.expand_dims(test_data, axis=-1)\n",
    "\n",
    "# One-hot encoding: lo utilize para evitar usar las etiquetas a modo str y mejor usar numeros :D\n",
    "train_labels_cat = to_categorical(train_labels, num_classes=4)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=4)\n",
    "\n",
    "# aqui puse como se distribuyen las clases en las carpetas, lo podriamos hacer de manera manual simplemente llendo a las carpetas, pero crei mejor poder verlo mediante el codigo.\n",
    "# ademas, en unos videos que utilize para el proyecto se menciona que nos permite ver en un grafico de manera mas comoda si hay mas imagenes de una categoria o otra.\n",
    "plt.figure(figsize=(8,4))\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # azul, naranja, verde, rojo\n",
    "\n",
    "counts = [np.sum(train_labels == i) for i in range(4)]\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=label_names, y=counts, palette=colors)\n",
    "plt.title(\"Distribucion de clases en el set de entrenamiento\", fontsize=14)\n",
    "plt.xlabel(\"Clase\", fontsize=12)\n",
    "plt.ylabel(\"Número de imágenes\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# hacemos la cnn: lo hice de solo 10 epocas porque la verdad era demasiado tardado con mas (lo hice con 50 pero demoro mucho)\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.fit(train_data, train_labels_cat, epochs=10, batch_size=32,\n",
    "              validation_split=0.2)\n",
    "\n",
    "# evaluamos la red cnn\n",
    "cnn_preds = np.argmax(cnn_model.predict(test_data), axis=1)\n",
    "print(\"=== CNN Classification Report ===\")\n",
    "print(classification_report(test_labels, cnn_preds, target_names=label_names))\n",
    "\n",
    "# MODELO RANDOM FOREST\n",
    "# Aplanar imágenes para modelo clásico\n",
    "train_data_flat = train_data.reshape(len(train_data), -1)\n",
    "test_data_flat = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(train_data_flat, train_labels)\n",
    "rf_preds = rf_model.predict(test_data_flat)\n",
    "\n",
    "print(\"♦♦♦ Informe de clasificacion de Random Forest ♦♦♦\")\n",
    "print(classification_report(test_labels, rf_preds, target_names=label_names))\n",
    "\n",
    "\n",
    "# Matrices de confusion\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(confusion_matrix(test_labels, cnn_preds), annot=True, fmt='d', cmap='plasma')\n",
    "plt.title('Matriz de confucion de la CNN ☻')\n",
    "plt.xticks(ticks=[0.5,1.5,2.5,3.5], labels=label_names)\n",
    "plt.yticks(ticks=[0.5,1.5,2.5,3.5], labels=label_names)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(confusion_matrix(test_labels, rf_preds), annot=True, fmt='d', cmap='magma')\n",
    "plt.title('Matriz de confusion del Random Forest ☻')\n",
    "plt.xticks(ticks=[0.5,1.5,2.5,3.5], labels=label_names)\n",
    "plt.yticks(ticks=[0.5,1.5,2.5,3.5], labels=label_names)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ef278-dba0-4770-abe0-4b778018f711",
   "metadata": {},
   "source": [
    "### 1) Analisis del dataset\n",
    "Para nuestro caso particular he decidido utilizar el dataset de brain tumor de 4 categorias (no confie en buscar otro de la red por cuestiones de tiempo), el dataset contiene 7,023 imagenes en formato .jpg, organizadas en una jerarquia de carpetas dentro de dos principales subcarpetas: la de  “Training” y “Testing”, que a su vez contienen mas subcarpetas para cada clase (glioma, meningioma, notumor y pituitary). Cada carpeta representa una categoría correspondiente al tipo de imagen de resonancia magnetica. Una de las tareas claves del analisis fue analizar primero la distribución de clases en el conjunto de entrenamiento, lo cual se visualizó mediante un gráfico de barras de colores diferenciados (algo recomendado en varias fuentes). \n",
    "Esta sencilla grafica nos permitio confirmar que las clases estan distribuidas de forma relativamente balanceada, aunque con ligeras diferencias en la cantidad de imagens por categoria. Esto es crucial para entender posibles sesgos en el dataset, ya que una desproporcion marcada entre clases podria afectar el rendimiento y la imparcialidad de los modelos predictivos. Ademas, se implemento una funcion para cargar, redimensionar y preprocesar las imagenes, facilitando su posterior uso en ls modelos de aprendizaje. La redimensión a un tamaño uniforme asegura que todos los modelos puedan procesar las imagenes eficientemente y sin errores por diferencias de forma.\n",
    "\n",
    "### 2) Identificacion del tipo de problema (clasificacion o regresion)\n",
    "Al analizar como se estructura el dataset, donde cada imagen esta asociada a una etiqueta que indica su clase correspondiente (glioma, meningioma, notumor, pituitary), es muy evidente que estamos frente a un problema de clasificacion supervisada (de muchas clases: multiclase). En este tipo de problemas, el objetivo del modelo es aprender patrones discriminativos que le permitan predecir correctamente la clase de una nueva imagen no vista previamente (cabe señalar que aqui radica la importancia de dividir los datos en grupos de entrenamiento/prueba, ya que de no hacerlo podemos caer en el underfitting u overfitting, lo cual no haria generalizable nuestro proyecto). A diferencia de los problemas de regresion, donde la variable objetivo es continua (o mejor dicho “numerica”), en este caso la variable objetivo es una categoria (se trata de una cualidad y no de un numero). La naturaleza supervisada del problema implica que contamos con ejemplos etiquetados durante el entrenamiento, lo cual permite entrenar modelos con retroalimentacion directa sobre sus predicciones.\n",
    "\n",
    "### 3) Creacion de Propuestas de Modelos Supervisados y su Implementación\r\n",
    "Ya una vez que fue identificado el tipo de problema, se procedio a seleccionar e implementar modelos supervisados adecuados para la tarea de la clasificacion de las imagenes. En este caso comparamos dos modelos: uno basado en aprendizaje profundo mediante la Red neuronal convolucional (CNN), y otro basado en aprendizaje automatico tradicional mediante un clasificador random forest. \r\n",
    "Sabemos que las CNN estan diseñadas específicamente para procesar imagenes, gracias a su capacidad de extraer caracteristicas espaciales mediante diferentes capas y filtros. La estructura de la red consiste en multiples capas, funciones ReLU, capas de pooling para reducir la dimensionalidad, y capas densas al final para realizar la clasificacion. Por el otro lado, el modelo random forest (aunque no fue diseñado originalmente para imagenes) se utilizp como un punto de comparacion luego de transformar las imagenes a vectores planos. Esto permitio evaluar la diferencia en desempeño entre las CNN y los modelos mas generales (como el random forest), y tambien mostro como distintas metodologias pueden ser aplicadas al mismo problema de clasificacion. Ambos modelos fueron entrenados utilizando el conjunto de entrenamiento y luego evaluados en el conjunto de prueba\n",
    "### 4) Evaluacion de Resultados Acorde al Problema\r\n",
    "Las metricas de evaluacion fueron: accuracy, precision, recall y f1-score. \r\n",
    "No las coloque en ningun grafico en especial, pero es posible visualizarlas en la ventana de ejecucion de Pycharm. Ademas los valores de las variables para realizar los calculos se obtienen de las matrices de confusion al final del codigo (ver link de Dri o ejecutar el codigo en Pycharmve)\n",
    "### 5) Analisis de los Resultados (VER LINK DE DRIVE O EJECUTAR EL CODIGO EN PYCHARM)\r\n",
    "Los resultados obtenidos a partir de la evaluacion de ambos modelos indican que la CNN supero significativamente al modelo Random forest en terminos de precision global y rendimiento por clase. en la matriz de confusion de la CNN se observa una mayor cantidad de predicciones correctas para cada una de las clases, especialmente para la categoria “notumor”, donde casi todas las imagenes fueron correctamente clasificadas. Ademas, el número de errores de clasificacion cruzada fue notablemente menor. En cambio, el random forest mostro dificultades mas marcadas, especialmente confundiendo imagenes entre las clases glioma y meningioma, y tambien presento mas errores con las imagenes de la clase pituitary. Este comportamiento se justifica tecnicamente por la naturaleza del modelo: la CNN es capaz de extraer caracteristicas jerarquicas y espaciales de las imagenes, mientras que el Random forest, al trabajar con vectores planos, pierde dicha estructura visual. Por tanto, se concluye que el mejor resultado fue proporcionado por la CNN, ya que logra capturar la complejidad del dominio visual y proporciona una clasificacion mas precisa y confiable, algo esencial en el contexto medico de diagnostico por imagen. La verdad era algo de esperarse ya que las CNN estan especialmente enfocadas al analisis de las imagenes.\n",
    "### 6) interpretabilidad de los Resultados\r\n",
    "En los videos y diferentes paginas de internet se suele mencionar que las CNN son una especie de “cajas negras” debido a su complejidad interna, los resultados obtenidos son interpretables desde un puntos de vista clinicos tanto tecnicos. La visualizacion mediante matrices de confusion facilita la interpretacion de los errores y aciertos por clase, permitiendo entender en que areas el modelo es fuerte y en cuales necesita mejora (como en la vida siempre se puede mejorar :D). Ademas, la distribucion de clases y los resultados metricos ofrecen una vision clara del rendimiento global del modelo. Si quisieramos aumentar la interpretabilidad, podrian aplicarse tecnicas adicionales como mapas de activacion (Grad-CaM, que se menciono en uno de los videos pero no me queda del todo claro como funcionan) para visualizar que regiones de la imagen influyen en la decision del modelo. Sin embargo, incluso sin estas tecnicas avanzadas, la clasificacion por CNN se muestra como una herramienta efectiva y relativamente comprensible cuando se acompaña de buenas visualizaciones y metricas. En este proyecto, la interpretacion de los resultados se logro mediante una adecuada presentacion grafica y el analisis de metricas clave, haciendo que los hallazgos puedan ser comprendidos incluso por profesionales no expertos en ciencia de datos, como medicos o investigadores del area de salud\n",
    "\n",
    "\n",
    "# CONCLUSION: Las computadoras me dan miedo ya que pueden saber mis gustos por lo que subo o veo en redes :(\n",
    "### .\r\n",
    "\r\n",
    ".\r\n",
    ".\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
